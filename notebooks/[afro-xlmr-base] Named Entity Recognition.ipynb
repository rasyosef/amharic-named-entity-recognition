{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup**"
      ],
      "metadata": {
        "id": "n9AqV2DZlhmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --quiet datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "ia8Z81C2lluP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhuwcf0dT-tV",
        "outputId": "f14f115b-59c8-4094-9f84-726835332912"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Dataset**"
      ],
      "metadata": {
        "id": "aGO-_xcPYros"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ner_dataset = load_dataset(\"rasyosef/amharic-named-entity-recognition\", split=\"train\")\n",
        "ner_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYpmORD3lKh7",
        "outputId": "993773da-9e6a-425a-cdf8-8cedef437f6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['tokens', 'ner_tags'],\n",
              "    num_rows: 3465\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_dataset.features[\"ner_tags\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa2b5aa-b699-45db-c5a4-02ed38c5e3fd",
        "id": "YdZq8laUug9s"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-TIME', 'I-TIME', 'B-TTL', 'I-TTL'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ner_dataset.features[\"ner_tags\"].feature.names\n",
        "\n",
        "label2id = {\n",
        "  label: i for i, label in enumerate(categories)\n",
        "}\n",
        "\n",
        "id2label = {\n",
        "  v: k for k, v in label2id.items()\n",
        "}\n",
        "\n",
        "print(id2label)\n",
        "print(label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOC2sM6IZ5jE",
        "outputId": "374b3917-b9e1-4d5c-ddd6-a06c43afae69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-TIME', 8: 'I-TIME', 9: 'B-TTL', 10: 'I-TTL'}\n",
            "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-TIME': 7, 'I-TIME': 8, 'B-TTL': 9, 'I-TTL': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Processing the data**"
      ],
      "metadata": {
        "id": "0yP79KkosRRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"Davlan/afro-xlmr-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
        "\n",
        "print(tokenizer.tokenize(\"ከሀገራቸው ከኢትዮጵያ ከወጡ ግማሽ ምዕተ <mask> ተቆጥሯል።\"))"
      ],
      "metadata": {
        "id": "yfwbnQRAqnkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408c3aee-ab9a-4533-e0ac-fd842de0b5b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁ከ', 'ሀ', 'ገ', 'ራቸው', '▁ከኢትዮጵያ', '▁ከ', 'ወጡ', '▁', 'ግማሽ', '▁', 'ምዕ', 'ተ', ' <mask>', '▁ተ', 'ቆ', 'ጥ', 'ሯል።']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.is_fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4svkjc1ugLg",
        "outputId": "10d6a909-5744-4cc7-aa45-df886771c1f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the pretokenized input by adding is_split_into_words=True\n",
        "inputs = tokenizer(ner_dataset[0][\"tokens\"], is_split_into_words=True)\n",
        "print(inputs.tokens())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V38s0LCovbfq",
        "outputId": "d20baa66-8369-4eb1-f571-89f8d8cabe53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁ኢ', 'ዴ', 'ፓ', '▁በየ', 'ክል', 'ሉ', '▁በሚ', 'ንቀሳቀስ', 'በት', '▁ጊዜ', '▁ሁሉ', '▁የ', 'ሀገሪቱ', 'ን', '▁አ', 'ጠቃ', 'ላይ', '▁ሕግ', 'እን', 'ዲ', 'ሁ', 'ም', '▁የ', 'አካባቢ', 'ውን', '▁ባህል', 'ና', '▁ቋንቋ', '▁አክ', 'ብሮ', '▁በ', 'አካባቢ', 'ው', '▁የሚገኙ', '▁የፖለቲካ', '▁ድርጅቶች', 'ንም', '▁አክ', 'ብሮ', 'ና', '▁መብ', 'ታቸውን', '▁', 'ጠብ', 'ቆ', '▁በ', 'ጨ', 'ዋ', 'ነት', '▁ያስተ', 'ም', 'ራል', '▁፣', '▁ይ', 'ማ', 'ራል', '\"', '▁ብ', 'ለ', 'ዋል', '▁።', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.word_ids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC2lXWPFwXYA",
        "outputId": "234476bc-eade-433f-918d-fd6b6c169bd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 9, 9, 10, 11, 11, 12, 12, 12, 13, 14, 15, 15, 16, 16, 16, 17, 17, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 21, 22, 22, 22, 22, 23, 23, 23, 24, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "  new_labels = []\n",
        "  current_word = None\n",
        "  for word_id in word_ids:\n",
        "    if word_id != current_word: # start of new word\n",
        "      current_word = word_id\n",
        "      label = -100 if word_id is None else labels[word_id]\n",
        "      new_labels.append(label)\n",
        "    elif word_id is None: # special token\n",
        "      new_labels.append(-100)\n",
        "    else:\n",
        "      # same word as pervious token\n",
        "      label = labels[word_id]\n",
        "      # If label is B-XXX change it to I-XXX\n",
        "      if id2label[label].startswith(\"B-\"):\n",
        "        label = label2id[\"I-\" + id2label[label][2:]]\n",
        "      new_labels.append(label)\n",
        "  return new_labels\n"
      ],
      "metadata": {
        "id": "OIa_VM_dxCx2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ner_dataset[2][\"ner_tags\"]\n",
        "inputs = tokenizer(ner_dataset[2][\"tokens\"], is_split_into_words=True)\n",
        "word_ids = inputs.word_ids()\n",
        "print(inputs.tokens())\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPzRWNgY0yri",
        "outputId": "c2259738-8b56-4e30-a0fc-99258421e8e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁በ', 'ባህ', 'ር', '▁', 'ዳር', '▁ዩኒቨርስቲ', 'ና', '▁በ', 'ጅ', 'ማ', '▁', 'መም', 'ህ', 'ራን', '▁ኮ', 'ሌ', 'ጅ', '▁ለ', 'ነ', 'ባር', '▁ተማሪዎች', '▁የምግብ', 'ና', '▁የመ', 'ኝ', 'ታ', '▁አገልግሎት', '▁ሊያ', 'ቆም', '▁እንደሚችል', '▁ባለፈው', '▁ዓመት', '▁የተሰጠ', 'ው', '▁ማሳ', 'ሰ', 'ቢያ', '▁ከዚህ', '▁ዓመት', '▁ጀምሮ', '▁ተግባራዊ', '▁ይሆናል', '▁በመ', 'ባሉ', '▁ተማሪዎች', '▁ከፍተኛ', '▁ስጋት', 'ና', '▁ጭ', 'ን', 'ቀት', '▁ላይ', '▁', 'መው', 'ደ', 'ቃቸው', 'ን', '▁ተጠ', 'ቆመ', '▁።', '</s>']\n",
            "[3, 4, 4, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[-100, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "  tokenized_inputs = tokenizer(\n",
        "      examples['tokens'], truncation=True, is_split_into_words=True\n",
        "  )\n",
        "  all_labels = examples['ner_tags']\n",
        "  new_labels = []\n",
        "  for i, labels in enumerate(all_labels):\n",
        "    word_ids = tokenized_inputs.word_ids(i)\n",
        "    new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "  tokenized_inputs['labels'] = new_labels\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "O6b6nxY90523"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = ner_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=ner_dataset.column_names,\n",
        ")\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWWTbm0O2kuJ",
        "outputId": "dc417646-fcbb-4799-95d9-6698b586b8ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 3465\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_datasets = tokenized_datasets.train_test_split(test_size=0.2, seed=16)\n",
        "preprocessed_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45zrhuSH5DyZ",
        "outputId": "7f260bf9-1f18-465c-af9a-c72ea93f3a37"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2772\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 693\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finetuning**"
      ],
      "metadata": {
        "id": "EwDwqk0o3ADg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Collator\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "QXLuKGS4266f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator([preprocessed_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiy4-2YM4wVa",
        "outputId": "82b469e8-2f27-4194-b3f2-b2b8b4ee6ad1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    5,    6,    6,    6,    6,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100],\n",
              "        [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Metrics**"
      ],
      "metadata": {
        "id": "tzL4QaUf5kOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet seqeval"
      ],
      "metadata": {
        "id": "D-F57rtZ5BaX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "wbVCvvg05oPw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = preprocessed_datasets[\"train\"][3][\"labels\"]\n",
        "print(labels)\n",
        "labels = [categories[i] for i in labels[1:-1]]\n",
        "print(labels), labels[19]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xgoOron6IsR",
        "outputId": "cc694192-1a93-4477-ee6e-7dafdcb1afa3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 'O')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = labels.copy()\n",
        "predictions[19] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itEbz8Es6pnB",
        "outputId": "50bc9979-2d0c-4c44-843c-f2479519b9a5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall_precision': 0.0,\n",
              " 'overall_recall': 0.0,\n",
              " 'overall_f1': 0.0,\n",
              " 'overall_accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[categories[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [categories[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "oofrKD5k5_J_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining the Model**"
      ],
      "metadata": {
        "id": "6TL296h17xCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_id,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqRVh0RU6E7k",
        "outputId": "8f530cb3-9d0a-46be-aeca-268214402284"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of labels\n",
        "model.config.num_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Ps4F9L8DTY",
        "outputId": "34eae5d1-6bf2-4834-e9b5-538a9a59a008"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fine-tuning the model**"
      ],
      "metadata": {
        "id": "Rjp7qPrX8KIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"xlm-roberta-base-finetuned-ner\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=4e-5,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    num_train_epochs=8,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        ")"
      ],
      "metadata": {
        "id": "TsJ76C4n8GWU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=preprocessed_datasets[\"train\"],\n",
        "    eval_dataset=preprocessed_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "-fW0EjIc8Wxw",
        "outputId": "ce7625be-a995-45ed-d915-683e1ba74e1d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-a428f15b8292>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1392' max='1392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1392/1392 17:25, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.396700</td>\n",
              "      <td>0.143722</td>\n",
              "      <td>0.537436</td>\n",
              "      <td>0.588103</td>\n",
              "      <td>0.561629</td>\n",
              "      <td>0.956048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.122900</td>\n",
              "      <td>0.112239</td>\n",
              "      <td>0.662062</td>\n",
              "      <td>0.699214</td>\n",
              "      <td>0.680131</td>\n",
              "      <td>0.965656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.079500</td>\n",
              "      <td>0.109457</td>\n",
              "      <td>0.686035</td>\n",
              "      <td>0.755331</td>\n",
              "      <td>0.719017</td>\n",
              "      <td>0.966730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.057000</td>\n",
              "      <td>0.118011</td>\n",
              "      <td>0.686627</td>\n",
              "      <td>0.772166</td>\n",
              "      <td>0.726889</td>\n",
              "      <td>0.968110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.039800</td>\n",
              "      <td>0.121568</td>\n",
              "      <td>0.667616</td>\n",
              "      <td>0.789001</td>\n",
              "      <td>0.723251</td>\n",
              "      <td>0.966321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.028800</td>\n",
              "      <td>0.134387</td>\n",
              "      <td>0.692683</td>\n",
              "      <td>0.796857</td>\n",
              "      <td>0.741127</td>\n",
              "      <td>0.967369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.022000</td>\n",
              "      <td>0.150307</td>\n",
              "      <td>0.695257</td>\n",
              "      <td>0.773288</td>\n",
              "      <td>0.732200</td>\n",
              "      <td>0.967445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.017400</td>\n",
              "      <td>0.156636</td>\n",
              "      <td>0.710526</td>\n",
              "      <td>0.787879</td>\n",
              "      <td>0.747206</td>\n",
              "      <td>0.967522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1392, training_loss=0.09552604097059403, metrics={'train_runtime': 1049.0926, 'train_samples_per_second': 21.138, 'train_steps_per_second': 1.327, 'total_flos': 1440282838129776.0, 'train_loss': 0.09552604097059403, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "9_BlWoSaJO_e",
        "outputId": "6f3e7399-3552-415a-a270-16048cd434b6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [44/44 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.15663553774356842,\n",
              " 'eval_precision': 0.7105263157894737,\n",
              " 'eval_recall': 0.7878787878787878,\n",
              " 'eval_f1': 0.7472059606173496,\n",
              " 'eval_accuracy': 0.9675218480094036,\n",
              " 'eval_runtime': 6.114,\n",
              " 'eval_samples_per_second': 113.346,\n",
              " 'eval_steps_per_second': 7.197,\n",
              " 'epoch': 8.0}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing**"
      ],
      "metadata": {
        "id": "weSApfhgs5jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner_pipe = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
      ],
      "metadata": {
        "id": "OGTljwXf8MUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65318ba3-3b98-4630-c390-480cf1bfc1b3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 3\n",
        "text = \" \".join(ner_dataset[ind][\"tokens\"])\n",
        "print(text)\n",
        "print(\" \".join([str(i) for i in ner_dataset[ind][\"ner_tags\"]]))\n",
        "ner_pipe(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17492c92-6229-49dd-ff6a-9da84d9a3c10",
        "id": "4lPsfy5y8MUR"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "የሻዕቢያው መሪ ለዚህ ማስፈራሪያቸው እንደ አብነት የተጠቀሙበት ኦጋዴንን ሲሆን የኢሕአዴግ መንግሥት ከቅኝ ግዛት ውሎቹ ላፈንግጥ ቢል ያንን ግዛት ለዘለዓለሙ ሊያጣው እንደሚችል ግልጽ ሊሆንለት ይገባል ሲሉ አስጠንቅቀዋል ።\n",
            "3 0 0 0 0 0 0 5 0 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'ORG',\n",
              "  'score': 0.99083966,\n",
              "  'word': 'የሻዕቢያው',\n",
              "  'start': 0,\n",
              "  'end': 6},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.98627806,\n",
              "  'word': 'ኦጋዴንን',\n",
              "  'start': 40,\n",
              "  'end': 45},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9901884,\n",
              "  'word': 'የኢሕአዴግ መንግሥት',\n",
              "  'start': 50,\n",
              "  'end': 62}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 12\n",
        "text = \" \".join(ner_dataset[ind][\"tokens\"])\n",
        "print(text)\n",
        "print(\" \".join([str(i) for i in ner_dataset[ind][\"ner_tags\"]]))\n",
        "ner_pipe(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aaf970a-0ece-4148-8cb4-f26f95a33e0d",
        "id": "OeCLAIqV8MUS"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "በናዝሬት አጠቃላይ ዕድሮች የመሰብሰቢያ አዳራሽ በተካሄደው በዚሁ ስብሰባ ላይ በአዳራሽ ውስጥ በመቀመጥና በመቆም ፣ ከውጭም በመስኮት ቁጥሩ እስከ 1400 የሆነ ሕዝብ መገኘቱን የገለጡት አቶ ልደቱ መታፈስ ሊኖር ይችላል\" የሚል ማስፈራሪያ በከተማው ተሠራጭቶ የነበረ ቢሆንም ቁጥራቸው የበዛ ወጣቶች ጐልማሶችና አዛውንቶች በስብሰባው ላይ መካፈላቸውን ፣ ብዙውም በአዳራሽ ጥበት ምክንያትም መመለሱን አመልክተዋል ።\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'TTL',\n",
              "  'score': 0.99643517,\n",
              "  'word': 'አቶ',\n",
              "  'start': 117,\n",
              "  'end': 119},\n",
              " {'entity_group': 'PER',\n",
              "  'score': 0.99778813,\n",
              "  'word': 'ልደቱ',\n",
              "  'start': 120,\n",
              "  'end': 123}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GIBZx56LOLOD"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}
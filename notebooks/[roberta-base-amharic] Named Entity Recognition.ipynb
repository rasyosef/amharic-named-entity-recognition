{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup**"
      ],
      "metadata": {
        "id": "n9AqV2DZlhmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --quiet datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "ia8Z81C2lluP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhuwcf0dT-tV",
        "outputId": "569d3a01-2832-4275-c0fd-fd11c70de8ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Dataset**"
      ],
      "metadata": {
        "id": "aGO-_xcPYros"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ner_dataset = load_dataset(\"rasyosef/amharic-named-entity-recognition\", split=\"train\")\n",
        "ner_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYpmORD3lKh7",
        "outputId": "ac0ac8f8-d757-49e4-c5a4-04e3d9018f52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['tokens', 'ner_tags'],\n",
              "    num_rows: 3465\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_dataset.features[\"ner_tags\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a90748-a7ae-4e18-c8f6-e8cbf3ce0669",
        "id": "YdZq8laUug9s"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-TIME', 'I-TIME', 'B-TTL', 'I-TTL'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ner_dataset.features[\"ner_tags\"].feature.names\n",
        "\n",
        "label2id = {\n",
        "  label: i for i, label in enumerate(categories)\n",
        "}\n",
        "\n",
        "id2label = {\n",
        "  v: k for k, v in label2id.items()\n",
        "}\n",
        "\n",
        "print(id2label)\n",
        "print(label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOC2sM6IZ5jE",
        "outputId": "45db4fac-c9dc-47ec-a31c-2fd0a687912a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-TIME', 8: 'I-TIME', 9: 'B-TTL', 10: 'I-TTL'}\n",
            "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-TIME': 7, 'I-TIME': 8, 'B-TTL': 9, 'I-TTL': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Processing the data**"
      ],
      "metadata": {
        "id": "0yP79KkosRRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"rasyosef/roberta-base-amharic\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
        "\n",
        "print(tokenizer.tokenize(\"ከሀገራቸው ከኢትዮጵያ ከወጡ ግማሽ ምዕተ <mask> ተቆጥሯል።\"))"
      ],
      "metadata": {
        "id": "yfwbnQRAqnkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abff397b-d44a-4240-ab28-ad01addb9381"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁ከ', 'ሀገራቸው', '▁ከኢትዮጵያ', '▁ከወጡ', '▁ግማሽ', '▁ምዕተ', ' <mask>', '▁ተቆጥ', 'ሯል።']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.is_fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4svkjc1ugLg",
        "outputId": "cf48595b-e061-4b39-b8c8-06770a30bebb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the pretokenized input by adding is_split_into_words=True\n",
        "inputs = tokenizer(ner_dataset[0][\"tokens\"], is_split_into_words=True)\n",
        "print(inputs.tokens())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V38s0LCovbfq",
        "outputId": "0d43c363-23c4-4d0c-f205-a5bc42dbaa79"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁ኢዴፓ', '▁በየክልሉ', '▁በሚ', 'ንቀሳቀስ', 'በት', '▁ጊዜ', '▁ሁሉ', '▁የሀገሪቱን', '▁አጠቃላይ', '▁ሕግ', 'እንዲሁም', '▁የአካባቢውን', '▁ባህልና', '▁ቋንቋ', '▁አክብሮ', '▁በአካባቢው', '▁የሚገኙ', '▁የፖለቲካ', '▁ድርጅቶችን', 'ም', '▁አክብሮ', 'ና', '▁መብታቸውን', '▁ጠብቆ', '▁በ', 'ጨዋ', 'ነት', '▁ያስተምራል', '▁', '፣', '▁ይማራል', '\"', '▁ብለዋል', '▁', '።', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.word_ids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC2lXWPFwXYA",
        "outputId": "620394ce-547f-42bf-9198-671aafdfaed8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 15, 16, 16, 17, 18, 19, 19, 19, 20, 21, 21, 22, 22, 23, 24, 24, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "  new_labels = []\n",
        "  current_word = None\n",
        "  for word_id in word_ids:\n",
        "    if word_id != current_word: # start of new word\n",
        "      current_word = word_id\n",
        "      label = -100 if word_id is None else labels[word_id]\n",
        "      new_labels.append(label)\n",
        "    elif word_id is None: # special token\n",
        "      new_labels.append(-100)\n",
        "    else:\n",
        "      # same word as pervious token\n",
        "      label = labels[word_id]\n",
        "      # If label is B-XXX change it to I-XXX\n",
        "      if id2label[label].startswith(\"B-\"):\n",
        "        label = label2id[\"I-\" + id2label[label][2:]]\n",
        "      new_labels.append(label)\n",
        "  return new_labels\n"
      ],
      "metadata": {
        "id": "OIa_VM_dxCx2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ner_dataset[2][\"ner_tags\"]\n",
        "inputs = tokenizer(ner_dataset[2][\"tokens\"], is_split_into_words=True)\n",
        "word_ids = inputs.word_ids()\n",
        "print(inputs.tokens())\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPzRWNgY0yri",
        "outputId": "996709c1-7523-46a2-bb92-0ec194f908f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁በባህር', '▁ዳር', '▁ዩኒቨርስቲ', 'ና', '▁በጅማ', '▁መምህራን', '▁ኮሌጅ', '▁ለነ', 'ባር', '▁ተማሪዎች', '▁የምግብ', 'ና', '▁የመኝታ', '▁አገልግሎት', '▁ሊያ', 'ቆም', '▁እንደሚችል', '▁ባለፈው', '▁ዓመት', '▁የተሰጠው', '▁ማሳሰቢያ', '▁ከዚህ', '▁ዓመት', '▁ጀምሮ', '▁ተግባራዊ', '▁ይሆናል', '▁በመ', 'ባሉ', '▁ተማሪዎች', '▁ከፍተኛ', '▁ስጋት', 'ና', '▁ጭንቀት', '▁ላይ', '▁', 'መውደቃቸው', 'ን', '▁ተጠቆመ', '▁', '።', '</s>']\n",
            "[3, 4, 4, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[-100, 3, 4, 4, 4, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "  tokenized_inputs = tokenizer(\n",
        "      examples['tokens'], truncation=True, is_split_into_words=True\n",
        "  )\n",
        "  all_labels = examples['ner_tags']\n",
        "  new_labels = []\n",
        "  for i, labels in enumerate(all_labels):\n",
        "    word_ids = tokenized_inputs.word_ids(i)\n",
        "    new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "  tokenized_inputs['labels'] = new_labels\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "O6b6nxY90523"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = ner_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=ner_dataset.column_names,\n",
        ")\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWWTbm0O2kuJ",
        "outputId": "4fd01765-45d8-4b02-897b-c89f6d81f081"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 3465\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_datasets = tokenized_datasets.train_test_split(test_size=0.2, seed=16)\n",
        "preprocessed_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45zrhuSH5DyZ",
        "outputId": "e3f67ffc-2c3a-4dbb-d74e-6f0108658946"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2772\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 693\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finetuning**"
      ],
      "metadata": {
        "id": "EwDwqk0o3ADg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Collator\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "QXLuKGS4266f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator([preprocessed_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiy4-2YM4wVa",
        "outputId": "f2cdb95f-35b8-427f-f01a-76df1fea45fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    5,    6,    6,    6,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0, -100],\n",
              "        [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Metrics**"
      ],
      "metadata": {
        "id": "tzL4QaUf5kOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet seqeval"
      ],
      "metadata": {
        "id": "D-F57rtZ5BaX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "wbVCvvg05oPw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = preprocessed_datasets[\"train\"][3][\"labels\"]\n",
        "print(labels)\n",
        "labels = [categories[i] for i in labels[1:-1]]\n",
        "print(labels), labels[19]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xgoOron6IsR",
        "outputId": "72410b5b-3341-48b5-a620-c2ea7dc8f70f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 'O')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = labels.copy()\n",
        "predictions[19] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itEbz8Es6pnB",
        "outputId": "97b9956b-adc9-4e08-b142-7b8509f8e67d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall_precision': 0.0,\n",
              " 'overall_recall': 0.0,\n",
              " 'overall_f1': 0.0,\n",
              " 'overall_accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[categories[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [categories[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "oofrKD5k5_J_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining the Model**"
      ],
      "metadata": {
        "id": "6TL296h17xCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_id,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqRVh0RU6E7k",
        "outputId": "69cd4b8a-ec89-4692-ae6c-fef33b9b66e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at rasyosef/roberta-base-amharic and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of labels\n",
        "model.config.num_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Ps4F9L8DTY",
        "outputId": "973babce-15b5-46a2-b600-6240a9302c4f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fine-tuning the model**"
      ],
      "metadata": {
        "id": "Rjp7qPrX8KIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"xlm-roberta-base-finetuned-ner\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=5e-5,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    num_train_epochs=8,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "TsJ76C4n8GWU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=preprocessed_datasets[\"train\"],\n",
        "    eval_dataset=preprocessed_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "-fW0EjIc8Wxw",
        "outputId": "05e4d476-8dcf-4240-ce69-d973fcd73947"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-efbf7a4a7c5a>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1392' max='1392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1392/1392 10:24, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.218100</td>\n",
              "      <td>0.110020</td>\n",
              "      <td>0.609658</td>\n",
              "      <td>0.680135</td>\n",
              "      <td>0.642971</td>\n",
              "      <td>0.961615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.073200</td>\n",
              "      <td>0.107563</td>\n",
              "      <td>0.713203</td>\n",
              "      <td>0.739618</td>\n",
              "      <td>0.726171</td>\n",
              "      <td>0.966668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.039300</td>\n",
              "      <td>0.139403</td>\n",
              "      <td>0.687234</td>\n",
              "      <td>0.725028</td>\n",
              "      <td>0.705625</td>\n",
              "      <td>0.965989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>0.148391</td>\n",
              "      <td>0.699459</td>\n",
              "      <td>0.726150</td>\n",
              "      <td>0.712555</td>\n",
              "      <td>0.964971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.011900</td>\n",
              "      <td>0.146824</td>\n",
              "      <td>0.741525</td>\n",
              "      <td>0.785634</td>\n",
              "      <td>0.762943</td>\n",
              "      <td>0.968704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>0.171483</td>\n",
              "      <td>0.732252</td>\n",
              "      <td>0.810325</td>\n",
              "      <td>0.769313</td>\n",
              "      <td>0.968855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.175868</td>\n",
              "      <td>0.747390</td>\n",
              "      <td>0.803591</td>\n",
              "      <td>0.774473</td>\n",
              "      <td>0.969383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.183561</td>\n",
              "      <td>0.748697</td>\n",
              "      <td>0.805836</td>\n",
              "      <td>0.776216</td>\n",
              "      <td>0.969383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1392, training_loss=0.04669905702273051, metrics={'train_runtime': 625.8569, 'train_samples_per_second': 35.433, 'train_steps_per_second': 2.224, 'total_flos': 983047760691336.0, 'train_loss': 0.04669905702273051, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "9_BlWoSaJO_e",
        "outputId": "708a6973-e747-43eb-9868-7174b3c45eee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [44/44 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.1835612654685974,\n",
              " 'eval_precision': 0.748696558915537,\n",
              " 'eval_recall': 0.8058361391694725,\n",
              " 'eval_f1': 0.7762162162162162,\n",
              " 'eval_accuracy': 0.9693827532898458,\n",
              " 'eval_runtime': 4.2649,\n",
              " 'eval_samples_per_second': 162.489,\n",
              " 'eval_steps_per_second': 10.317,\n",
              " 'epoch': 8.0}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing**"
      ],
      "metadata": {
        "id": "weSApfhgs5jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner_pipe = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
      ],
      "metadata": {
        "id": "OGTljwXf8MUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fad2a46-b041-425e-cbd1-d11eb7eee5f7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 3\n",
        "text = \" \".join(ner_dataset[ind][\"tokens\"])\n",
        "print(text)\n",
        "print(\" \".join([str(i) for i in ner_dataset[ind][\"ner_tags\"]]))\n",
        "ner_pipe(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a3b9d4-dc8b-47d2-c4c3-2af36050b940",
        "id": "4lPsfy5y8MUR"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "የሻዕቢያው መሪ ለዚህ ማስፈራሪያቸው እንደ አብነት የተጠቀሙበት ኦጋዴንን ሲሆን የኢሕአዴግ መንግሥት ከቅኝ ግዛት ውሎቹ ላፈንግጥ ቢል ያንን ግዛት ለዘለዓለሙ ሊያጣው እንደሚችል ግልጽ ሊሆንለት ይገባል ሲሉ አስጠንቅቀዋል ።\n",
            "3 0 0 0 0 0 0 5 0 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'ORG',\n",
              "  'score': 0.99936485,\n",
              "  'word': 'የሻዕቢያው',\n",
              "  'start': 0,\n",
              "  'end': 6},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9986171,\n",
              "  'word': 'ኦጋዴንን',\n",
              "  'start': 40,\n",
              "  'end': 45},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.99921405,\n",
              "  'word': 'የኢሕአዴግ መንግሥት',\n",
              "  'start': 50,\n",
              "  'end': 62}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 12\n",
        "text = \" \".join(ner_dataset[ind][\"tokens\"])\n",
        "print(text)\n",
        "print(\" \".join([str(i) for i in ner_dataset[ind][\"ner_tags\"]]))\n",
        "ner_pipe(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "befa910a-5964-4db8-e069-021ea08d9f53",
        "id": "OeCLAIqV8MUS"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "በናዝሬት አጠቃላይ ዕድሮች የመሰብሰቢያ አዳራሽ በተካሄደው በዚሁ ስብሰባ ላይ በአዳራሽ ውስጥ በመቀመጥና በመቆም ፣ ከውጭም በመስኮት ቁጥሩ እስከ 1400 የሆነ ሕዝብ መገኘቱን የገለጡት አቶ ልደቱ መታፈስ ሊኖር ይችላል\" የሚል ማስፈራሪያ በከተማው ተሠራጭቶ የነበረ ቢሆንም ቁጥራቸው የበዛ ወጣቶች ጐልማሶችና አዛውንቶች በስብሰባው ላይ መካፈላቸውን ፣ ብዙውም በአዳራሽ ጥበት ምክንያትም መመለሱን አመልክተዋል ።\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'TTL',\n",
              "  'score': 0.9998541,\n",
              "  'word': 'አቶ',\n",
              "  'start': 117,\n",
              "  'end': 119},\n",
              " {'entity_group': 'PER',\n",
              "  'score': 0.9998771,\n",
              "  'word': 'ልደቱ',\n",
              "  'start': 120,\n",
              "  'end': 123}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GIBZx56LOLOD"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Setup**"
      ],
      "metadata": {
        "id": "n9AqV2DZlhmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --quiet datasets evaluate accelerate"
      ],
      "metadata": {
        "id": "ia8Z81C2lluP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip uninstall -y wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhuwcf0dT-tV",
        "outputId": "c0bbf860-dcff-4e06-b56f-fbcc35757d7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Dataset**"
      ],
      "metadata": {
        "id": "aGO-_xcPYros"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ner_dataset = load_dataset(\"rasyosef/amharic-named-entity-recognition\", split=\"train\")\n",
        "ner_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYpmORD3lKh7",
        "outputId": "499796d7-ea9a-417a-9fac-2a73c72f99dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:86: UserWarning: \n",
            "Access to the secret `HF_TOKEN` has not been granted on this notebook.\n",
            "You will not be requested again.\n",
            "Please restart the session if you want to be prompted again.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['tokens', 'ner_tags'],\n",
              "    num_rows: 3465\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_dataset.features[\"ner_tags\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587ac967-5ea4-4fb1-83b0-4cdc87699325",
        "id": "YdZq8laUug9s"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-TIME', 'I-TIME', 'B-TTL', 'I-TTL'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ner_dataset.features[\"ner_tags\"].feature.names\n",
        "\n",
        "label2id = {\n",
        "  label: i for i, label in enumerate(categories)\n",
        "}\n",
        "\n",
        "id2label = {\n",
        "  v: k for k, v in label2id.items()\n",
        "}\n",
        "\n",
        "print(id2label)\n",
        "print(label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOC2sM6IZ5jE",
        "outputId": "b824e6b4-2a25-449b-b2eb-2764b8fce1d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-TIME', 8: 'I-TIME', 9: 'B-TTL', 10: 'I-TTL'}\n",
            "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-TIME': 7, 'I-TIME': 8, 'B-TTL': 9, 'I-TTL': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Processing the data**"
      ],
      "metadata": {
        "id": "0yP79KkosRRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"Davlan/afro-xlmr-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
        "\n",
        "print(tokenizer.tokenize(\"ከሀገራቸው ከኢትዮጵያ ከወጡ ግማሽ ምዕተ <mask> ተቆጥሯል።\"))"
      ],
      "metadata": {
        "id": "yfwbnQRAqnkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db75cd2d-a4e0-41fb-c966-bd981305ed9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁ከ', 'ሀ', 'ገ', 'ራቸው', '▁ከኢትዮጵያ', '▁ከ', 'ወጡ', '▁', 'ግማሽ', '▁', 'ምዕ', 'ተ', ' <mask>', '▁ተ', 'ቆ', 'ጥ', 'ሯል።']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.is_fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4svkjc1ugLg",
        "outputId": "71f9d542-436a-45dc-8014-d4290c570c34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the pretokenized input by adding is_split_into_words=True\n",
        "inputs = tokenizer(ner_dataset[0][\"tokens\"], is_split_into_words=True)\n",
        "print(inputs.tokens())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V38s0LCovbfq",
        "outputId": "c1580623-01dc-4744-b198-fac1e1ccdf28"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁ኢ', 'ዴ', 'ፓ', '▁በየ', 'ክል', 'ሉ', '▁በሚ', 'ንቀሳቀስ', 'በት', '▁ጊዜ', '▁ሁሉ', '▁የ', 'ሀገሪቱ', 'ን', '▁አ', 'ጠቃ', 'ላይ', '▁ሕግ', 'እን', 'ዲ', 'ሁ', 'ም', '▁የ', 'አካባቢ', 'ውን', '▁ባህል', 'ና', '▁ቋንቋ', '▁አክ', 'ብሮ', '▁በ', 'አካባቢ', 'ው', '▁የሚገኙ', '▁የፖለቲካ', '▁ድርጅቶች', 'ንም', '▁አክ', 'ብሮ', 'ና', '▁መብ', 'ታቸውን', '▁', 'ጠብ', 'ቆ', '▁በ', 'ጨ', 'ዋ', 'ነት', '▁ያስተ', 'ም', 'ራል', '▁፣', '▁ይ', 'ማ', 'ራል', '\"', '▁ብ', 'ለ', 'ዋል', '▁።', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.word_ids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC2lXWPFwXYA",
        "outputId": "4f0a86bd-355d-4ea4-cf6a-02cc7c4d0272"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 9, 9, 10, 11, 11, 12, 12, 12, 13, 14, 15, 15, 16, 16, 16, 17, 17, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 21, 22, 22, 22, 22, 23, 23, 23, 24, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "  new_labels = []\n",
        "  current_word = None\n",
        "  for word_id in word_ids:\n",
        "    if word_id != current_word: # start of new word\n",
        "      current_word = word_id\n",
        "      label = -100 if word_id is None else labels[word_id]\n",
        "      new_labels.append(label)\n",
        "    elif word_id is None: # special token\n",
        "      new_labels.append(-100)\n",
        "    else:\n",
        "      # same word as pervious token\n",
        "      label = labels[word_id]\n",
        "      # If label is B-XXX change it to I-XXX\n",
        "      if id2label[label].startswith(\"B-\"):\n",
        "        label = label2id[\"I-\" + id2label[label][2:]]\n",
        "      new_labels.append(label)\n",
        "  return new_labels\n"
      ],
      "metadata": {
        "id": "OIa_VM_dxCx2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ner_dataset[2][\"ner_tags\"]\n",
        "inputs = tokenizer(ner_dataset[2][\"tokens\"], is_split_into_words=True)\n",
        "word_ids = inputs.word_ids()\n",
        "print(inputs.tokens())\n",
        "print(labels)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPzRWNgY0yri",
        "outputId": "c1462f87-b4b0-4725-fe08-9f57e429273c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁በ', 'ባህ', 'ር', '▁', 'ዳር', '▁ዩኒቨርስቲ', 'ና', '▁በ', 'ጅ', 'ማ', '▁', 'መም', 'ህ', 'ራን', '▁ኮ', 'ሌ', 'ጅ', '▁ለ', 'ነ', 'ባር', '▁ተማሪዎች', '▁የምግብ', 'ና', '▁የመ', 'ኝ', 'ታ', '▁አገልግሎት', '▁ሊያ', 'ቆም', '▁እንደሚችል', '▁ባለፈው', '▁ዓመት', '▁የተሰጠ', 'ው', '▁ማሳ', 'ሰ', 'ቢያ', '▁ከዚህ', '▁ዓመት', '▁ጀምሮ', '▁ተግባራዊ', '▁ይሆናል', '▁በመ', 'ባሉ', '▁ተማሪዎች', '▁ከፍተኛ', '▁ስጋት', 'ና', '▁ጭ', 'ን', 'ቀት', '▁ላይ', '▁', 'መው', 'ደ', 'ቃቸው', 'ን', '▁ተጠ', 'ቆመ', '▁።', '</s>']\n",
            "[3, 4, 4, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[-100, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "  tokenized_inputs = tokenizer(\n",
        "      examples['tokens'], truncation=True, is_split_into_words=True\n",
        "  )\n",
        "  all_labels = examples['ner_tags']\n",
        "  new_labels = []\n",
        "  for i, labels in enumerate(all_labels):\n",
        "    word_ids = tokenized_inputs.word_ids(i)\n",
        "    new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "  tokenized_inputs['labels'] = new_labels\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "O6b6nxY90523"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = ner_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=ner_dataset.column_names,\n",
        ")\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWWTbm0O2kuJ",
        "outputId": "05a1cb2e-c0a4-4408-d715-e9096f8ff35b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 3465\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_datasets = tokenized_datasets.train_test_split(test_size=0.2, seed=16)\n",
        "preprocessed_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45zrhuSH5DyZ",
        "outputId": "1087dc73-b03e-42f6-b4fb-545dc1773bb2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2772\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 693\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finetuning**"
      ],
      "metadata": {
        "id": "EwDwqk0o3ADg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Collator\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "QXLuKGS4266f"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator([preprocessed_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiy4-2YM4wVa",
        "outputId": "eb30df09-a4e4-4e2c-e05c-729eb53ab63e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    5,    6,    6,    6,    6,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100],\n",
              "        [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Metrics**"
      ],
      "metadata": {
        "id": "tzL4QaUf5kOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet seqeval"
      ],
      "metadata": {
        "id": "D-F57rtZ5BaX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "wbVCvvg05oPw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = preprocessed_datasets[\"train\"][3][\"labels\"]\n",
        "print(labels)\n",
        "labels = [categories[i] for i in labels[1:-1]]\n",
        "print(labels), labels[19]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xgoOron6IsR",
        "outputId": "574ebc3d-3715-4825-ac5e-fba97119acb0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 'O')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = labels.copy()\n",
        "predictions[19] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itEbz8Es6pnB",
        "outputId": "56d5fee5-6a68-4280-f5c2-8cf91d78a907"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall_precision': 0.0,\n",
              " 'overall_recall': 0.0,\n",
              " 'overall_f1': 0.0,\n",
              " 'overall_accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[categories[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [categories[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "oofrKD5k5_J_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining the Model**"
      ],
      "metadata": {
        "id": "6TL296h17xCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_id,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqRVh0RU6E7k",
        "outputId": "b6d98cb3-09d5-4edc-c769-23820af589ea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at Davlan/afro-xlmr-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of labels\n",
        "model.config.num_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Ps4F9L8DTY",
        "outputId": "bf68eb08-6eb9-4a7a-d06d-c581a37b567d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fine-tuning the model**"
      ],
      "metadata": {
        "id": "Rjp7qPrX8KIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"xlm-roberta-base-finetuned-ner\",\n",
        "    per_device_train_batch_size=12,\n",
        "    per_device_eval_batch_size=12,\n",
        "    learning_rate=4e-5,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    num_train_epochs=8,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        ")"
      ],
      "metadata": {
        "id": "TsJ76C4n8GWU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=preprocessed_datasets[\"train\"],\n",
        "    eval_dataset=preprocessed_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "-fW0EjIc8Wxw",
        "outputId": "8b6d9099-f9cf-4313-a062-9dd25e678b24"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-efbf7a4a7c5a>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1848' max='1848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1848/1848 49:19, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>0.119639</td>\n",
              "      <td>0.612648</td>\n",
              "      <td>0.695847</td>\n",
              "      <td>0.651603</td>\n",
              "      <td>0.964072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.105200</td>\n",
              "      <td>0.103572</td>\n",
              "      <td>0.658111</td>\n",
              "      <td>0.719416</td>\n",
              "      <td>0.687399</td>\n",
              "      <td>0.967726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.072000</td>\n",
              "      <td>0.116639</td>\n",
              "      <td>0.662289</td>\n",
              "      <td>0.792368</td>\n",
              "      <td>0.721513</td>\n",
              "      <td>0.965605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.046300</td>\n",
              "      <td>0.126028</td>\n",
              "      <td>0.698000</td>\n",
              "      <td>0.783389</td>\n",
              "      <td>0.738234</td>\n",
              "      <td>0.968263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.029700</td>\n",
              "      <td>0.136629</td>\n",
              "      <td>0.707661</td>\n",
              "      <td>0.787879</td>\n",
              "      <td>0.745619</td>\n",
              "      <td>0.968902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.142083</td>\n",
              "      <td>0.704457</td>\n",
              "      <td>0.815937</td>\n",
              "      <td>0.756110</td>\n",
              "      <td>0.969183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.010600</td>\n",
              "      <td>0.161811</td>\n",
              "      <td>0.722782</td>\n",
              "      <td>0.804714</td>\n",
              "      <td>0.761551</td>\n",
              "      <td>0.970282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.006800</td>\n",
              "      <td>0.166965</td>\n",
              "      <td>0.730533</td>\n",
              "      <td>0.800224</td>\n",
              "      <td>0.763792</td>\n",
              "      <td>0.970307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1848, training_loss=0.06699519756036404, metrics={'train_runtime': 2963.2361, 'train_samples_per_second': 7.484, 'train_steps_per_second': 0.624, 'total_flos': 4849543903169448.0, 'train_loss': 0.06699519756036404, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "9_BlWoSaJO_e",
        "outputId": "18793c31-6c48-4324-cec9-18d4933e5074"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [58/58 00:16]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.16696497797966003,\n",
              " 'eval_precision': 0.7305327868852459,\n",
              " 'eval_recall': 0.8002244668911336,\n",
              " 'eval_f1': 0.763792179967863,\n",
              " 'eval_accuracy': 0.9703071497930189,\n",
              " 'eval_runtime': 17.3374,\n",
              " 'eval_samples_per_second': 39.971,\n",
              " 'eval_steps_per_second': 3.345,\n",
              " 'epoch': 8.0}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing**"
      ],
      "metadata": {
        "id": "weSApfhgs5jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner_pipe = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
      ],
      "metadata": {
        "id": "OGTljwXf8MUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc44458e-af61-4fd4-cff1-9f605fd19e0c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 3\n",
        "text = \" \".join(ner_dataset[ind][\"tokens\"])\n",
        "print(text)\n",
        "print(\" \".join([str(i) for i in ner_dataset[ind][\"ner_tags\"]]))\n",
        "ner_pipe(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337265ff-1d08-4337-96b3-6ccd907d657f",
        "id": "4lPsfy5y8MUR"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "የሻዕቢያው መሪ ለዚህ ማስፈራሪያቸው እንደ አብነት የተጠቀሙበት ኦጋዴንን ሲሆን የኢሕአዴግ መንግሥት ከቅኝ ግዛት ውሎቹ ላፈንግጥ ቢል ያንን ግዛት ለዘለዓለሙ ሊያጣው እንደሚችል ግልጽ ሊሆንለት ይገባል ሲሉ አስጠንቅቀዋል ።\n",
            "3 0 0 0 0 0 0 5 0 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'ORG',\n",
              "  'score': 0.9989479,\n",
              "  'word': 'የሻዕቢያው',\n",
              "  'start': 0,\n",
              "  'end': 6},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9986769,\n",
              "  'word': 'ኦጋዴንን',\n",
              "  'start': 40,\n",
              "  'end': 45},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.99818915,\n",
              "  'word': 'የኢሕአዴግ መንግሥት',\n",
              "  'start': 50,\n",
              "  'end': 62}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 12\n",
        "text = \" \".join(ner_dataset[ind][\"tokens\"])\n",
        "print(text)\n",
        "print(\" \".join([str(i) for i in ner_dataset[ind][\"ner_tags\"]]))\n",
        "ner_pipe(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33eab4bf-de59-4c00-c155-e1f0ef134f14",
        "id": "OeCLAIqV8MUS"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "በናዝሬት አጠቃላይ ዕድሮች የመሰብሰቢያ አዳራሽ በተካሄደው በዚሁ ስብሰባ ላይ በአዳራሽ ውስጥ በመቀመጥና በመቆም ፣ ከውጭም በመስኮት ቁጥሩ እስከ 1400 የሆነ ሕዝብ መገኘቱን የገለጡት አቶ ልደቱ መታፈስ ሊኖር ይችላል\" የሚል ማስፈራሪያ በከተማው ተሠራጭቶ የነበረ ቢሆንም ቁጥራቸው የበዛ ወጣቶች ጐልማሶችና አዛውንቶች በስብሰባው ላይ መካፈላቸውን ፣ ብዙውም በአዳራሽ ጥበት ምክንያትም መመለሱን አመልክተዋል ።\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'TTL',\n",
              "  'score': 0.9998479,\n",
              "  'word': 'አቶ',\n",
              "  'start': 117,\n",
              "  'end': 119},\n",
              " {'entity_group': 'PER',\n",
              "  'score': 0.9998122,\n",
              "  'word': 'ልደቱ',\n",
              "  'start': 120,\n",
              "  'end': 123}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GIBZx56LOLOD"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}